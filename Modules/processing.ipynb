{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import numpy as np\n",
    "import Modules.photo_processing as pp\n",
    "import cv2\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import net_sphere\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"--net\": 'sphere20a',\n",
    "        \n",
    "        \"--model\": 'drive/My Drive/for_sphereface/sphere20a.pth'}\n",
    "\n",
    "face_template = np.load('drive/My Drive/for_sphereface/face_template.npy')\n",
    "predictor = dlib.shape_predictor('drive/My Drive/for_sphereface/shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INNER_EYES_AND_BOTTOM_LIP = [38, 44, 30, 49, 54]\n",
    "\n",
    "def embeddings_evaluation(img, landmarks):    \n",
    "\n",
    " img_part = pp.alignment(img, landmarks[INNER_EYES_AND_BOTTOM_LIP])\n",
    "      \n",
    " imglist = [img_part,cv2.flip(img_part,1)]\n",
    " for i in range(len(imglist)):\n",
    "        imglist[i] = imglist[i].transpose(2, 0, 1).reshape((1,3,112,96))\n",
    "        imglist[i] = (imglist[i]-127.5)/128.0\n",
    " img_part = np.vstack(imglist)\n",
    " with torch.no_grad():\n",
    "       img_part = Variable(torch.from_numpy(img_part).float()).cuda()\n",
    "       #img_part = Variable(torch.from_numpy(img_part).float())\n",
    " output = net(img_part)\n",
    "      \n",
    " f =  output.cpu().data.numpy()\n",
    " #f =  output.data.numpy()\n",
    " emb = np.float64(f[0])\n",
    " #emb = f\n",
    "   \n",
    " return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = getattr(net_sphere,args['--net'])()\n",
    "net.load_state_dict(torch.load(args['--model']))\n",
    "net.cuda()\n",
    "net.eval()\n",
    "net.feature = True\n",
    "\n",
    "\n",
    "dataset_path = Path('drive/My Drive/Datasets/lfw-deepfunneled')    \n",
    "    \n",
    "    \n",
    "res = {}\n",
    "\n",
    "for person in dataset_path.glob('*'):\n",
    "  for img_path in person.glob('*.*'):\n",
    "    name = img_path.stem\n",
    "    print(name)\n",
    "    img = cv2.imread(str(img_path))\n",
    "    try:\n",
    "      face_rect = pp.face_detection(img)\n",
    "      landmarks = pp.landmarks_extracting(img, face_rect[0])\n",
    "      embs = embeddings_evaluation(img, landmarks)\n",
    "      res[name] = {\n",
    "            'landmarks': landmarks.tolist(), \n",
    "            'embs': list(embs)\n",
    "        }\n",
    "    except:\n",
    "       print(\"Error!\")   \n",
    "    \n",
    "\n",
    "\n",
    "with open('res.txt', 'w') as json_file:\n",
    "      json.dump(res, json_file)"
   ]
  }
 ]
}